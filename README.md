# CausalMoE
Granger Causal Discovery (GCD) is fundamental for analyzing temporal dependencies in complex systems. However, existing neural GCD methods predominantly rely on a "one-size-fits-all" paradigm that struggles to capture the distribution shifts and dynamic regime changes inherent in real-world time series, leading to entangled and spurious causal graphs. In this paper, we propose CausalMoE, a billion-scale multimodal Granger causal foundation model that explicitly models patch-level heterogeneity and enables zero-shot causal inference. CausalMoE introduces a pattern-routed mixture of heterogeneous experts, which identifies latent temporal patterns and routes each patch to specialized domain experts to separate regime-specific mechanisms from shared dynamics. For interpretable graph recovery, we design causality-aware self-attention operating across variables, yielding sparse Granger causal graphs via proximal optimization. Furthermore, CausalMoE is the first to integrate LLMs and VLMs to align numerical signals with textual and visual priors, regularizing causal estimation in complex scenarios. Experiments on synthetic and real-world benchmark datasets demonstrate that CausalMoE outperforms existing state-of-the-art methods in Granger causal discovery under few-shot settings.
